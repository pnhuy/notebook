{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import catboost\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope \n",
    "\n",
    "HYPEROPT_ALGO = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECTIVES\n",
    "MOMENT_FEATURES = True\n",
    "KNN_FEATURES = False\n",
    "LOGREG_FEATURES = False\n",
    "RF_FEATURES = False\n",
    "ADA_FEATURES = False\n",
    "NB_FEATURES = False\n",
    "SVC_FEATURES = False\n",
    "MLP_FEATURES = False\n",
    "XGB_FEATURES = False\n",
    "\n",
    "FT_IMP_SELECTION = False\n",
    "\n",
    "N_CATBOOST_SEARCH = 200\n",
    "N_XGBOOST_SEARCH = 5000\n",
    "N_RF_SEARCH = 500\n",
    "\n",
    "TRAIN_PATH = 'data/train.csv'\n",
    "TEST_PATH = 'data/test.csv'\n",
    "USERS_PATH = 'data/users.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_ls = ['subject_line_length',\n",
    "       'last_open_day', 'last_login_day', 'last_checkout_day',\n",
    "       'open_count_last_10_days', 'open_count_last_30_days',\n",
    "       'open_count_last_60_days', 'login_count_last_10_days',\n",
    "       'login_count_last_30_days', 'login_count_last_60_days',\n",
    "       'checkout_count_last_10_days', 'checkout_count_last_30_days',\n",
    "       'checkout_count_last_60_days']\n",
    "users_cols = ['attr_1', 'attr_2', 'attr_3', 'age', 'domain']\n",
    "\n",
    "agg_1_cols = ['last_open_day', 'last_login_day', 'last_checkout_day',\n",
    "       'open_count_last_10_days', 'open_count_last_30_days',\n",
    "       'open_count_last_60_days', 'login_count_last_10_days',\n",
    "       'login_count_last_30_days', 'login_count_last_60_days',\n",
    "       'checkout_count_last_10_days', 'checkout_count_last_30_days',\n",
    "       'checkout_count_last_60_days']\n",
    "agg_2_cols = ['weekday', 'attr_1', 'attr_2', 'attr_3', 'age', 'domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH, na_values=['Never open', 'Never checkout', 'Never login'])\n",
    "test_df = pd.read_csv(TEST_PATH, na_values=['Never open', 'Never checkout', 'Never login'])\n",
    "users_df = pd.read_csv(USERS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_df = train_df.set_index('user_id').join(users_df.set_index('user_id'))\n",
    "test_user_df = test_df.set_index('user_id').join(users_df.set_index('user_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_1_cols = ['last_open_day', 'last_login_day']\n",
    "# agg_2_cols = ['weekday', 'domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['weekday'] = pd.to_datetime(df.grass_date).dt.weekday\n",
    "#     df['dayofyear'] = pd.to_datetime(df.grass_date).dt.dayofyear\n",
    "#     df['daysinmonth'] = pd.to_datetime(df.grass_date).dt.daysinmonth\n",
    "#     df['is_leap_year'] = pd.to_datetime(df.grass_date).dt.is_leap_year.astype('int')\n",
    "#     df['is_month_end'] = pd.to_datetime(df.grass_date).dt.is_month_end.astype('int')\n",
    "#     df['is_month_start'] = pd.to_datetime(df.grass_date).dt.is_month_start.astype('int')\n",
    "#     df['is_quarter_end'] = pd.to_datetime(df.grass_date).dt.is_quarter_end.astype('int')\n",
    "#     df['is_quarter_start'] = pd.to_datetime(df.grass_date).dt.is_quarter_start.astype('int')\n",
    "    df['month'] = pd.to_datetime(df.grass_date).dt.month\n",
    "#     df['weekofyear'] = pd.to_datetime(df.grass_date).dt.weekofyear\n",
    "    \n",
    "    for col in column_ls+users_cols:\n",
    "        na_count = pd.isnull(df[col]).sum()\n",
    "        if na_count > 0:\n",
    "            na_col = col+'_isnull'\n",
    "            df[na_col] = pd.isnull(df[col]).astype('int')\n",
    "        if col in users_cols:\n",
    "            df[col] = df[col].fillna(-1)\n",
    "    \n",
    "    if MOMENT_FEATURES:\n",
    "        for agg_1_col in agg_1_cols:\n",
    "            for agg_2_col in agg_2_cols:\n",
    "                for agg_op in ['mean', 'std', 'min', 'max', 'median']:\n",
    "                    agg_name = agg_1_col + '__' + agg_2_col + '__' + agg_op\n",
    "                    if agg_op == 'mean':\n",
    "                        agg = df.groupby([agg_2_col])[agg_1_col].mean().rename(agg_name)\n",
    "                        df[agg_name] = df[[agg_1_col, agg_2_col]].set_index(agg_2_col).join(agg)[agg_name].tolist()\n",
    "                    elif agg_op == 'std':\n",
    "                        agg = df.groupby([agg_2_col])[agg_1_col].std().rename(agg_name)\n",
    "                        df[agg_name] = df[[agg_1_col, agg_2_col]].set_index(agg_2_col).join(agg)[agg_name].tolist()\n",
    "                    elif agg_op == 'min':\n",
    "                        agg = df.groupby([agg_2_col])[agg_1_col].min().rename(agg_name)\n",
    "                        df[agg_name] = df[[agg_1_col, agg_2_col]].set_index(agg_2_col).join(agg)[agg_name].tolist()\n",
    "                    elif agg_op == 'max':\n",
    "                        agg = df.groupby([agg_2_col])[agg_1_col].max().rename(agg_name)\n",
    "                        df[agg_name] = df[[agg_1_col, agg_2_col]].set_index(agg_2_col).join(agg)[agg_name].tolist()\n",
    "                    elif agg_op == 'median':\n",
    "                        agg = df.groupby([agg_2_col])[agg_1_col].median().rename(agg_name)\n",
    "                        df[agg_name] = df[[agg_1_col, agg_2_col]].set_index(agg_2_col).join(agg)[agg_name].tolist()\n",
    "    \n",
    "    df = df.fillna(9999)\n",
    "    df = df.drop(columns=['row_id', 'grass_date'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = pd.get_dummies(df, columns=['domain'])\n",
    "    df = df.drop(columns=['domain_other'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess(train_user_df)\n",
    "test = preprocess(test_user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73539, 397)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55970, 396)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FT Engr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train[train['month'] != 9].drop(columns=['open_flag', 'month'])\n",
    "y_train = train[train['month'] != 9].open_flag\n",
    "X_val_df = train[train['month'] == 9].drop(columns=['open_flag', 'month'])\n",
    "y_val = train[train['month'] == 9].open_flag\n",
    "X_test_df = test.drop(columns='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (66659, 395)\n",
      "y_train (66659,)\n",
      "X_val (6880, 395)\n",
      "y_val (6880,)\n",
      "X_test (55970, 395)\n"
     ]
    }
   ],
   "source": [
    "print('X_train', X_train_df.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_val', X_val_df.shape)\n",
    "print('y_val', y_val.shape)\n",
    "print('X_test', X_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scl = StandardScaler()\n",
    "X_train = scl.fit_transform(X_train_df)\n",
    "X_val = scl.transform(X_val_df)\n",
    "X_test = scl.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66659, 395)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66659,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FT_IMP_SELECTION:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    ft_imp = pd.DataFrame({\n",
    "        'col': X_train_df.columns,\n",
    "        'imp': clf.feature_importances_\n",
    "    })\n",
    "\n",
    "    ft_sort = ft_imp.sort_values(by='imp', ascending=False).reset_index(drop=True)\n",
    "    ft_sort['cumsum'] = ft_sort.imp.cumsum()\n",
    "    ft = ft_sort[ft_sort['cumsum'] < 0.905].col.tolist()\n",
    "    print(ft)\n",
    "    \n",
    "    X_train_df = train[train['month'] != 9].drop(columns=['open_flag', 'month'])[ft]\n",
    "    X_val_df = train[train['month'] == 9].drop(columns=['open_flag', 'month'])[ft]\n",
    "    X_test_df = test.drop(columns='month')[ft]\n",
    "\n",
    "    scl = StandardScaler()\n",
    "    X_train = scl.fit_transform(X_train_df)\n",
    "    X_val = scl.transform(X_val_df)\n",
    "    X_test = scl.transform(X_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (66659, 395)\n",
      "y_train (66659,)\n",
      "X_val (6880, 395)\n",
      "y_val (6880,)\n",
      "X_test (55970, 395)\n"
     ]
    }
   ],
   "source": [
    "print('X_train', X_train_df.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_val', X_val_df.shape)\n",
    "print('y_val', y_val.shape)\n",
    "print('X_test', X_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ft = dict()\n",
    "val_ft = dict()\n",
    "test_ft = dict()\n",
    "\n",
    "if KNN_FEATURES:\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn_models = dict()\n",
    "\n",
    "    for k in tqdm([5, 50, 500, 5000]):\n",
    "        knn_col = 'knn' + str(k)\n",
    "        knn_models[knn_col] = KNeighborsClassifier(n_neighbors=k, n_jobs=-1).fit(X_train, y_train)\n",
    "    \n",
    "    for k in tqdm(knn_models):\n",
    "        model = knn_models[k]\n",
    "        preds = model.predict(X_train)\n",
    "        new_ft[k] = preds\n",
    "    \n",
    "    for k in tqdm(knn_models):\n",
    "        model = knn_models[k]\n",
    "        preds = model.predict(X_val)\n",
    "        val_ft[k] = preds\n",
    "\n",
    "    for k in tqdm(knn_models):\n",
    "        model = knn_models[k]\n",
    "        preds = model.predict(X_test)\n",
    "        test_ft[k] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOGREG_FEATURES:\n",
    "    # LogisticRegression\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "    model.fit(X_train, y_train)\n",
    "    model_name = 'LogisticRegression'\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    new_ft[model_name] = y_train_pred\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_ft[model_name] = y_val_pred\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_ft[model_name] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RF_FEATURES:\n",
    "    # Random forest\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier()\n",
    "    model_name = 'RandomForestClassifier'\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    new_ft[model_name] = y_train_pred\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_ft[model_name] = y_val_pred\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_ft[model_name] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ADA_FEATURES:\n",
    "    # AdaBOOST\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    model = AdaBoostClassifier()\n",
    "    model_name = 'AdaBoostClassifier'\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    new_ft[model_name] = y_train_pred\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_ft[model_name] = y_val_pred\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_ft[model_name] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SVC_FEATURES:\n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC(kernel=\"linear\")\n",
    "    model_name = 'SVC'\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    new_ft[model_name] = y_train_pred\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_ft[model_name] = y_val_pred\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_ft[model_name] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NB_FEATURES:\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    model = GaussianNB()\n",
    "    model_name = 'GaussianNB'\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    new_ft[model_name] = y_train_pred\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_ft[model_name] = y_val_pred\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_ft[model_name] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLP_FEATURES:\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    model = MLPClassifier(alpha=0.1, max_iter=1000, early_stopping=True, n_iter_no_change=50)\n",
    "    model_name = 'MLPClassifier'\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    new_ft[model_name] = y_train_pred\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_ft[model_name] = y_val_pred\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_ft[model_name] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGB_FEATURES:\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model_name = 'XGBClassifier'\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    new_ft[model_name] = y_train_pred\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_ft[model_name] = y_val_pred\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_ft[model_name] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(new_ft) + len(val_ft) + len(test_ft) > 0:\n",
    "    for col, lst in new_ft.items():\n",
    "        X_train = np.append(X_train, lst.reshape(-1,1), axis=1)\n",
    "\n",
    "    for col, lst in val_ft.items():\n",
    "        X_val = np.append(X_val, lst.reshape(-1,1), axis=1)\n",
    "\n",
    "    for col, lst in test_ft.items():\n",
    "        X_test = np.append(X_test, lst.reshape(-1,1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (66659, 395)\n",
      "y_train (66659,)\n",
      "X_val (6880, 395)\n",
      "y_val (6880,)\n",
      "X_test (55970, 395)\n"
     ]
    }
   ],
   "source": [
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_val', X_val.shape)\n",
    "print('y_val', y_val.shape)\n",
    "print('X_test', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47579915097071235"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.searchcv import BayesSearchCV\n",
    "\n",
    "from skopt.callbacks import DeadlineStopper, VerboseCallback, DeltaXStopper\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Pool(X_train, y_train)\n",
    "val_data = Pool(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5109690977839323\n"
     ]
    }
   ],
   "source": [
    "base_model = CatBoostClassifier(task_type = \"GPU\", verbose=False)\n",
    "base_model.fit(X_train,y_train)\n",
    "preds_class = base_model.predict(val_data)\n",
    "print(matthews_corrcoef(y_val, preds_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_sub = catboost.Pool(X_test, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train = catboost.Pool(X_train, y_train)\n",
    "D_test = catboost.Pool(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'iterations': hp.uniform('iterations', 100, 5000),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -2.0, 0),\n",
    "    'depth': hp.quniform(\"depth\", 3, 8, 1),\n",
    "    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 3, 50),\n",
    "    'border_count': hp.uniform ('border_count', 1, 64),\n",
    "    'bagging_temperature': hp.uniform('bagging_temperature', 0.0, 1.0),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 0.9, 1.0),\n",
    "       }\n",
    "\n",
    "def get_catboost_params(space):\n",
    "    params = dict()\n",
    "    params['iterations'] = int(space['iterations'])\n",
    "    params['learning_rate'] = space['learning_rate']\n",
    "    params['depth'] = int(space['depth'])\n",
    "    params['l2_leaf_reg'] = space['l2_leaf_reg']\n",
    "    params['border_count'] = int(space['border_count'])\n",
    "    params['bagging_temperature'] = space['bagging_temperature']\n",
    "    params['scale_pos_weight'] = space['scale_pos_weight']\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    params = get_catboost_params(space)\n",
    "    model = catboost.CatBoostClassifier(iterations=params['iterations'],\n",
    "                                        learning_rate=params['learning_rate'],\n",
    "                                        depth=int(params['depth']),\n",
    "                                        loss_function='Logloss',\n",
    "                                        use_best_model=True,\n",
    "                                        task_type=\"GPU\",\n",
    "                                        eval_metric='MCC',\n",
    "                                        l2_leaf_reg=params['l2_leaf_reg'],\n",
    "                                        early_stopping_rounds=500,\n",
    "                                        border_count=params['border_count'],\n",
    "                                        bagging_temperature=params['bagging_temperature'],\n",
    "                                        scale_pos_weight=params['scale_pos_weight'],\n",
    "                                        od_type=\"Iter\",\n",
    "                                        verbose=False\n",
    "                                        )\n",
    "    \n",
    "    model.fit(D_train, eval_set=D_test, verbose=False)\n",
    "    y_pred = model.predict_proba(D_test.get_features())\n",
    "    test_loss = sklearn.metrics.log_loss(D_test.get_label(), y_pred, labels=[0, 1])\n",
    "    acc = sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(y_pred, axis=1))\n",
    "    auc = sklearn.metrics.roc_auc_score(D_test.get_label(), y_pred[:,1])\n",
    "    mcc = matthews_corrcoef(D_test.get_label(), np.argmax(y_pred, axis=1))\n",
    "\n",
    "    return{'loss':-mcc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:41<00:00,  1.71s/trial, best loss: -0.5356284078763499]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_cb = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_CATBOOST_SEARCH,\n",
    "                     trials=trials,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_temperature': 0.7497169755340393, 'border_count': 46.22616874915195, 'depth': 3.0, 'iterations': 1376.429093384665, 'l2_leaf_reg': 18.272379993248038, 'learning_rate': 0.7063005433614764, 'scale_pos_weight': 0.9314224762928681}\n"
     ]
    }
   ],
   "source": [
    "print(best_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cb.update({'border_count': int(best_cb['border_count'])})\n",
    "best_cb.update({'iterations': int(best_cb['iterations'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4940484\ttest: 0.5035394\tbest: 0.5035394 (0)\ttotal: 4.15ms\tremaining: 5.71s\n",
      "bestTest = 0.5327667006\n",
      "bestIteration = 34\n",
      "Shrink model to first 35 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f05857a85c0>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = catboost.CatBoostClassifier(loss_function='Logloss',\n",
    "                                    use_best_model=True,\n",
    "                                    task_type=\"GPU\",\n",
    "                                    eval_metric='MCC',\n",
    "                                    early_stopping_rounds=500,\n",
    "                                    od_type=\"Iter\",\n",
    "                                    verbose=2000,\n",
    "                                    **best_cb\n",
    "                                    )\n",
    "model.fit(D_train, eval_set=D_test, verbose=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.8889065114100247\n",
      "mcc =  0.5356284078763499\n",
      "loss =  0.26688234670453126\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_proba(D_test.get_features())\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(D_test.get_label(), pred[:,1]))\n",
    "print(\"mcc = \", sklearn.metrics.matthews_corrcoef(D_test.get_label(), np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(D_test.get_label(), pred, labels=[0, 1]))\n",
    "mcc_cb = sklearn.metrics.matthews_corrcoef(D_test.get_label(), np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'cb_{mcc_cb}.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =model.predict_proba(X_test)\n",
    "sub_label = np.argmax(sub, axis=1)\n",
    "sub_df = pd.read_csv('data/sample_submission_0_1.csv')\n",
    "sub_df['open_flag'] = sub_label\n",
    "sub_df.to_csv(f'sub_cb_val_{mcc_cb}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_space = {\n",
    "    'max_depth': hp.uniform('max_depth', 3, 30),\n",
    "    'min_samples_split': hp.uniform('min_samples_split', 2, 100),\n",
    "    'max_leaf_nodes': hp.uniform('max_leaf_nodes', 5, 25),\n",
    "    'min_samples_leaf': hp.uniform('min_samples_leaf', 5, 50),\n",
    "    'n_estimators': hp.uniform('n_estimators', 50, 1000),\n",
    "    'max_samples': hp.uniform('max_samples', 0.0, 1.0),\n",
    "    'max_features': hp.uniform('max_features', 0.0, 1.0)\n",
    "       }\n",
    "\n",
    "def get_rf_params(rf_space):\n",
    "    params = dict()\n",
    "    params['max_depth'] = int(rf_space['max_depth'])\n",
    "    params['min_samples_split'] = int(rf_space['min_samples_split'])\n",
    "    params['max_leaf_nodes'] = int(rf_space['max_leaf_nodes'])\n",
    "    params['min_samples_leaf'] = int(rf_space['min_samples_leaf'])\n",
    "    params['n_estimators'] = int(rf_space['n_estimators'])\n",
    "    params['max_samples'] = rf_space['max_samples']\n",
    "    params['max_features'] = rf_space['max_features']\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_call_count = 0\n",
    "cur_best_loss = np.inf\n",
    "\n",
    "def objective(rf_space):\n",
    "    params = get_rf_params(rf_space)\n",
    "    model = RandomForestClassifier(max_depth=params['max_depth'],\n",
    "                                    min_samples_split=params['min_samples_split'],\n",
    "                                    max_leaf_nodes=params['max_leaf_nodes'],\n",
    "                                    min_samples_leaf=params['min_samples_leaf'],\n",
    "                                    n_estimators=params['n_estimators'],\n",
    "                                    max_samples=params['max_samples'],\n",
    "                                    max_features=params['max_features'],\n",
    "                                    n_jobs=-1,\n",
    "                                    random_state=42\n",
    "                                    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)\n",
    "    pred_label = np.where(y_pred > 0.5, 1, 0)\n",
    "    test_loss = sklearn.metrics.log_loss(y_val, y_pred, labels=[0, 1])\n",
    "    acc = sklearn.metrics.accuracy_score(y_val, np.argmax(y_pred, axis=1))\n",
    "    auc = sklearn.metrics.roc_auc_score(y_val, y_pred[:,1])\n",
    "    mcc = matthews_corrcoef(y_val, np.argmax(y_pred, axis=1))\n",
    "\n",
    "    return{'loss':-mcc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [16:04<00:00,  1.93s/trial, best loss: -0.5075210345604432]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_rf = hyperopt.fmin(fn=objective,\n",
    "                     space=rf_space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_RF_SEARCH,\n",
    "                     trials=trials,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf['max_depth'] = int(best_rf['max_depth'])\n",
    "best_rf['min_samples_split'] = int(best_rf['min_samples_split'])\n",
    "best_rf['max_leaf_nodes'] = int(best_rf['max_leaf_nodes'])\n",
    "best_rf['min_samples_leaf'] = int(best_rf['min_samples_leaf'])\n",
    "best_rf['n_estimators'] = int(best_rf['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, max_features=0.9331650332166556,\n",
       "                       max_leaf_nodes=16, max_samples=0.20107640093697762,\n",
       "                       min_samples_leaf=28, min_samples_split=41,\n",
       "                       n_estimators=258, n_jobs=-1)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, **best_rf)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.8818327143143945\n",
      "mcc =  0.5015213252825286\n",
      "loss =  0.27871095530737533\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_proba(X_val)\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(y_val, pred[:,1]))\n",
    "print(\"mcc = \", sklearn.metrics.matthews_corrcoef(y_val, np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(y_val, pred, labels=[0, 1]))\n",
    "mcc_rf = sklearn.metrics.matthews_corrcoef(y_val, np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'rf_{mcc_rf}.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =model.predict_proba(X_test)\n",
    "sub_label = np.argmax(sub, axis=1)\n",
    "sub_df = pd.read_csv('data/sample_submission_0_1.csv')\n",
    "sub_df['open_flag'] = sub_label\n",
    "sub_df.to_csv(f'sub_rf_val_{mcc_rf}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xgb(space):\n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        booster='gbtree',\n",
    "        tree_method='gpu_hist',\n",
    "        nthread=-1,\n",
    "        n_estimators=space['n_estimators'],\n",
    "        eta=space['eta'],\n",
    "        max_depth=int(space['max_depth']),\n",
    "        min_child_weight=int(space['min_child_weight']),\n",
    "        gamma=space['gamma'],\n",
    "        colsample_bytree=space['colsample_bytree'],\n",
    "        scale_pos_weight=space['scale_pos_weight']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "xgb_space = {\n",
    "    'booster': hp.choice('booster', ['gbtree', 'gblinear']),\n",
    "    'n_estimators': scope.int(hp.uniform('n_estimators', 100, 1000)),\n",
    "    'eta': hp.loguniform('eta', -5.0, 3),\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 2, 20)),\n",
    "    'min_child_weight': scope.int(hp.uniform('min_child_weight', 1, 50)),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 50.0),\n",
    "    'subsample': hp.uniform('subsample', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.0, 1.0),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 0.0, 1.0),\n",
    "    }\n",
    "\n",
    "def get_xgb_params(space):\n",
    "    params = dict()\n",
    "    params['n_estimators'] = space['n_estimators']\n",
    "    params['eta'] = space['eta']\n",
    "    params['max_depth'] = space['max_depth']\n",
    "    params['min_child_weight'] = space['min_child_weight']\n",
    "    params['gamma'] = space['gamma']\n",
    "    params['subsample'] = space['subsample']\n",
    "    params['colsample_bytree'] = space['colsample_bytree']\n",
    "    params['scale_pos_weight'] = space['scale_pos_weight']\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    params = get_xgb_params(space)\n",
    "    model = build_xgb(params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)\n",
    "    pred_label = np.where(y_pred > 0.5, 1, 0)\n",
    "    test_loss = sklearn.metrics.log_loss(y_val, y_pred, labels=[0, 1])\n",
    "    acc = sklearn.metrics.accuracy_score(y_val, np.argmax(y_pred, axis=1))\n",
    "    auc = sklearn.metrics.roc_auc_score(y_val, y_pred[:,1])\n",
    "    mcc = sklearn.metrics.matthews_corrcoef(y_val, np.argmax(y_pred, axis=1))\n",
    "    \n",
    "    return{'loss':-mcc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [6:06:54<00:00,  4.40s/trial, best loss: -0.5463900126078486]   \n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_xgb = hyperopt.fmin(fn=objective,\n",
    "                     space=xgb_space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_XGBOOST_SEARCH,\n",
    "                     trials=trials,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 1, 'colsample_bytree': 0.8117933531497206, 'eta': 0.08840198872497015, 'gamma': 0.9580402932450544, 'max_depth': 2.30386257875966, 'min_child_weight': 20.02693734064389, 'n_estimators': 968.33514077476, 'scale_pos_weight': 0.9831028495929607, 'subsample': 0.6146205973547038}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-0.5429062310404649'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_xgb)\n",
    "\n",
    "{'colsample_bytree': 0.14070641610979773, 'eta': 1.1182226516769986, 'gamma': 5.336064981920235, 'max_depth': 13.011760013638906, 'min_child_weight': 19.393325052586604, 'scale_pos_weight': 0.9823427013639542, 'subsample': 0.10261415984429015}\n",
    "\n",
    "'-0.5429062310404649'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb['n_estimators'] = int(best_xgb['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8117933531497206,\n",
       "              eta=0.08840198872497015, gamma=0.9580402932450544, gpu_id=0,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.0884019881, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=20, missing=nan,\n",
       "              monotone_constraints='(0,0,0,0,0,...0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)',\n",
       "              n_estimators=968, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=0.9831028495929607, subsample=1,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_xgb(best_xgb)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.8866876631198555\n",
      "mcc =  0.5463900126078486\n",
      "loss =  0.2719779053870805\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_proba(X_val)\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(y_val, pred[:,1]))\n",
    "print(\"mcc = \", sklearn.metrics.matthews_corrcoef(y_val, np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(y_val, pred, labels=[0, 1]))\n",
    "mcc_xgb = sklearn.metrics.matthews_corrcoef(y_val, np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'xgb_{mcc_xgb}.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =model.predict_proba(X_test)\n",
    "sub_label = np.argmax(sub, axis=1)\n",
    "sub_df = pd.read_csv('data/sample_submission_0_1.csv')\n",
    "sub_df['open_flag'] = sub_label\n",
    "sub_df.to_csv(f'sub_xgb_val_{mcc_xgb}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_params = {'boosting_type': 'gbdt',\n",
    "                  'max_depth' : -1,\n",
    "                  'objective': 'binary',\n",
    "                  'nthread': -1, # Updated from nthread\n",
    "                  'num_leaves': 64,\n",
    "                  'learning_rate': 0.05,\n",
    "                  'max_bin': 512,\n",
    "                  'subsample_for_bin': 200,\n",
    "                  'subsample': 1,\n",
    "                  'subsample_freq': 1,\n",
    "                  'colsample_bytree': 0.8,\n",
    "                  'reg_alpha': 5,\n",
    "                  'reg_lambda': 10,\n",
    "                  'min_split_gain': 0.5,\n",
    "                  'min_child_weight': 1,\n",
    "                  'min_child_samples': 5,\n",
    "                  'scale_pos_weight': 1,\n",
    "                  'num_class' : 1,\n",
    "                  'metric' : 'binary_error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lgb(params):\n",
    "    model = lgb.LGBMClassifier(boosting_type= 'gbdt',\n",
    "                                objective = 'binary',\n",
    "                                n_jobs = -1, # Updated from 'nthread'\n",
    "                                silent = True,\n",
    "                                #device='gpu',\n",
    "                                max_depth = params['max_depth'],\n",
    "                                max_bin = params['max_bin'],\n",
    "                                subsample_for_bin = params['subsample_for_bin'],\n",
    "                                subsample = params['subsample'],\n",
    "                                subsample_freq = params['subsample_freq'],\n",
    "                                min_split_gain = params['min_split_gain'],\n",
    "                                min_child_weight = params['min_child_weight'],\n",
    "                                min_child_samples = params['min_child_samples'],\n",
    "                                scale_pos_weight = params['scale_pos_weight'],\n",
    "                                \n",
    "                                learning_rate=params['learning_rate'],\n",
    "                                n_estimators=params['n_estimators'],\n",
    "                                num_leaves=params['num_leaves'],\n",
    "                                colsample_bytree=params['colsample_bytree'],\n",
    "                                reg_alpha=params['reg_alpha'],\n",
    "                                reg_lambda=params['reg_lambda']\n",
    "                              )\n",
    "\n",
    "    return model\n",
    "\n",
    "lgb_space = {\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 2, 20)),\n",
    "    'max_bin': scope.int(hp.uniform('max_bin', 10, 500)),\n",
    "    'subsample_for_bin': scope.int(hp.uniform('subsample_for_bin', 10, 500)),\n",
    "    'subsample': hp.uniform('subsample', 0.1, 1.0),\n",
    "    'subsample_freq': hp.choice('subsample_freq', [0, 1]),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0.1, 1.0),\n",
    "    'min_child_weight': scope.int(hp.uniform('min_child_weight', 1, 20)),\n",
    "    'min_child_samples': scope.int(hp.uniform('min_child_samples', 1, 20)),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 0.1, 1.0),\n",
    "    \n",
    "    'learning_rate': hp.loguniform('learning_rate', -5.0, 1),\n",
    "    'n_estimators': scope.int(hp.uniform('n_estimators', 10, 1000)),\n",
    "    'num_leaves': scope.int(hp.uniform('num_leaves', 2, 100)),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.1, 10.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.1, 10.0)\n",
    "    \n",
    "    }\n",
    "\n",
    "def get_lgb_params(space):\n",
    "#     print(space)\n",
    "    params = dict()\n",
    "    params['max_depth'] = space['max_depth']\n",
    "    params['max_bin'] = space['max_bin']\n",
    "    params['subsample_for_bin'] = space['subsample_for_bin']\n",
    "    params['subsample'] = space['subsample']\n",
    "    params['subsample_freq'] = space['subsample_freq']\n",
    "    params['min_split_gain'] = space['min_split_gain']\n",
    "    params['min_child_weight'] = space['min_child_weight']\n",
    "    params['min_child_samples'] = space['min_child_samples']\n",
    "    params['scale_pos_weight'] = space['scale_pos_weight']\n",
    "\n",
    "    params['learning_rate']=space['learning_rate']\n",
    "    params['n_estimators']=space['n_estimators']\n",
    "    params['num_leaves']=space['num_leaves']\n",
    "    params['colsample_bytree']=space['colsample_bytree']\n",
    "    params['reg_alpha']=space['reg_alpha']\n",
    "    params['reg_lambda']=space['reg_lambda']\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_call_count = 0\n",
    "cur_best_loss = np.inf\n",
    "\n",
    "def objective(space):\n",
    "    params = get_lgb_params(space)\n",
    "    model = build_lgb(params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)\n",
    "    pred_label = np.where(y_pred > 0.5, 1, 0)\n",
    "    test_loss = sklearn.metrics.log_loss(y_val, y_pred, labels=[0, 1])\n",
    "    acc = sklearn.metrics.accuracy_score(y_val, np.argmax(y_pred, axis=1))\n",
    "    auc = sklearn.metrics.roc_auc_score(y_val, y_pred[:,1])\n",
    "    mcc = matthews_corrcoef(y_val, np.argmax(y_pred, axis=1))\n",
    "\n",
    "    return{'loss':-mcc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_lgb = hyperopt.fmin(fn=objective,\n",
    "                     space=lgb_space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=1000,\n",
    "                     trials=trials,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgb['max_depth'] = int(best_lgb['max_depth'])\n",
    "best_lgb['max_bin'] = int(best_lgb['max_bin'])\n",
    "best_lgb['subsample_for_bin'] = int(best_lgb['subsample_for_bin'])\n",
    "best_lgb['min_child_weight'] = int(best_lgb['min_child_weight'])\n",
    "best_lgb['min_child_samples'] = int(best_lgb['min_child_samples'])\n",
    "best_lgb['n_estimators']=int(best_lgb['n_estimators'])\n",
    "best_lgb['num_leaves']=int(best_lgb['num_leaves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_lgb(best_lgb)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(X_val)\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(y_val, pred[:,1]))\n",
    "print(\"mcc = \", sklearn.metrics.matthews_corrcoef(y_val, np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(y_val, pred, labels=[0, 1]))\n",
    "mcc_lgb = sklearn.metrics.matthews_corrcoef(y_val, np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'lgb_{mcc_lgb}.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =model.predict_proba(X_test)\n",
    "sub_label = np.argmax(sub, axis=1)\n",
    "sub_df = pd.read_csv('data/sample_submission_0_1.csv')\n",
    "sub_df['open_flag'] = sub_label\n",
    "sub_df.to_csv(f'sub_lgb_val_{mcc_lgb}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'CatBoost'\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "new_ft[model_name] = y_train_pred\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_ft[model_name] = y_val_pred\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_ft[model_name] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train = pd.DataFrame(new_ft)\n",
    "en_val = pd.DataFrame(val_ft)\n",
    "en_test = pd.DataFrame(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn5</th>\n",
       "      <th>knn50</th>\n",
       "      <th>knn500</th>\n",
       "      <th>knn5000</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>MLPClassifier</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>XGBClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716230</td>\n",
       "      <td>0.663867</td>\n",
       "      <td>0.551709</td>\n",
       "      <td>0.665778</td>\n",
       "      <td>0.605036</td>\n",
       "      <td>0.696128</td>\n",
       "      <td>0.629544</td>\n",
       "      <td>0.625050</td>\n",
       "      <td>0.717149</td>\n",
       "      <td>0.727090</td>\n",
       "      <td>0.722538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn50</th>\n",
       "      <td>0.716230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868556</td>\n",
       "      <td>0.709520</td>\n",
       "      <td>0.844415</td>\n",
       "      <td>0.494196</td>\n",
       "      <td>0.820278</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>0.702634</td>\n",
       "      <td>0.866120</td>\n",
       "      <td>0.819446</td>\n",
       "      <td>0.733129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn500</th>\n",
       "      <td>0.663867</td>\n",
       "      <td>0.868556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782221</td>\n",
       "      <td>0.889732</td>\n",
       "      <td>0.453222</td>\n",
       "      <td>0.790409</td>\n",
       "      <td>0.877775</td>\n",
       "      <td>0.675400</td>\n",
       "      <td>0.826961</td>\n",
       "      <td>0.768528</td>\n",
       "      <td>0.677816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn5000</th>\n",
       "      <td>0.551709</td>\n",
       "      <td>0.709520</td>\n",
       "      <td>0.782221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735098</td>\n",
       "      <td>0.374631</td>\n",
       "      <td>0.642194</td>\n",
       "      <td>0.815064</td>\n",
       "      <td>0.528501</td>\n",
       "      <td>0.671502</td>\n",
       "      <td>0.634526</td>\n",
       "      <td>0.555555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.665778</td>\n",
       "      <td>0.844415</td>\n",
       "      <td>0.889732</td>\n",
       "      <td>0.735098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.462473</td>\n",
       "      <td>0.814124</td>\n",
       "      <td>0.898788</td>\n",
       "      <td>0.715880</td>\n",
       "      <td>0.833682</td>\n",
       "      <td>0.770239</td>\n",
       "      <td>0.683712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.605036</td>\n",
       "      <td>0.494196</td>\n",
       "      <td>0.453222</td>\n",
       "      <td>0.374631</td>\n",
       "      <td>0.462473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502344</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.468817</td>\n",
       "      <td>0.506217</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>0.649491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.696128</td>\n",
       "      <td>0.820278</td>\n",
       "      <td>0.790409</td>\n",
       "      <td>0.642194</td>\n",
       "      <td>0.814124</td>\n",
       "      <td>0.502344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758159</td>\n",
       "      <td>0.728224</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.850873</td>\n",
       "      <td>0.752298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.629544</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>0.877775</td>\n",
       "      <td>0.815064</td>\n",
       "      <td>0.898788</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.758159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.647443</td>\n",
       "      <td>0.785304</td>\n",
       "      <td>0.730776</td>\n",
       "      <td>0.643281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.625050</td>\n",
       "      <td>0.702634</td>\n",
       "      <td>0.675400</td>\n",
       "      <td>0.528501</td>\n",
       "      <td>0.715880</td>\n",
       "      <td>0.468817</td>\n",
       "      <td>0.728224</td>\n",
       "      <td>0.647443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717257</td>\n",
       "      <td>0.680485</td>\n",
       "      <td>0.641304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.717149</td>\n",
       "      <td>0.866120</td>\n",
       "      <td>0.826961</td>\n",
       "      <td>0.671502</td>\n",
       "      <td>0.833682</td>\n",
       "      <td>0.506217</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.785304</td>\n",
       "      <td>0.717257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870604</td>\n",
       "      <td>0.766336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.727090</td>\n",
       "      <td>0.819446</td>\n",
       "      <td>0.768528</td>\n",
       "      <td>0.634526</td>\n",
       "      <td>0.770239</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>0.850873</td>\n",
       "      <td>0.730776</td>\n",
       "      <td>0.680485</td>\n",
       "      <td>0.870604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.722538</td>\n",
       "      <td>0.733129</td>\n",
       "      <td>0.677816</td>\n",
       "      <td>0.555555</td>\n",
       "      <td>0.683712</td>\n",
       "      <td>0.649491</td>\n",
       "      <td>0.752298</td>\n",
       "      <td>0.643281</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.766336</td>\n",
       "      <td>0.828723</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            knn5     knn50    knn500   knn5000  LogisticRegression  RandomForestClassifier  AdaBoostClassifier       SVC  GaussianNB  MLPClassifier  CatBoost  XGBClassifier\n",
       "knn5                    1.000000  0.716230  0.663867  0.551709            0.665778                0.605036            0.696128  0.629544    0.625050       0.717149  0.727090       0.722538\n",
       "knn50                   0.716230  1.000000  0.868556  0.709520            0.844415                0.494196            0.820278  0.809794    0.702634       0.866120  0.819446       0.733129\n",
       "knn500                  0.663867  0.868556  1.000000  0.782221            0.889732                0.453222            0.790409  0.877775    0.675400       0.826961  0.768528       0.677816\n",
       "knn5000                 0.551709  0.709520  0.782221  1.000000            0.735098                0.374631            0.642194  0.815064    0.528501       0.671502  0.634526       0.555555\n",
       "LogisticRegression      0.665778  0.844415  0.889732  0.735098            1.000000                0.462473            0.814124  0.898788    0.715880       0.833682  0.770239       0.683712\n",
       "RandomForestClassifier  0.605036  0.494196  0.453222  0.374631            0.462473                1.000000            0.502344  0.432547    0.468817       0.506217  0.540700       0.649491\n",
       "AdaBoostClassifier      0.696128  0.820278  0.790409  0.642194            0.814124                0.502344            1.000000  0.758159    0.728224       0.865417  0.850873       0.752298\n",
       "SVC                     0.629544  0.809794  0.877775  0.815064            0.898788                0.432547            0.758159  1.000000    0.647443       0.785304  0.730776       0.643281\n",
       "GaussianNB              0.625050  0.702634  0.675400  0.528501            0.715880                0.468817            0.728224  0.647443    1.000000       0.717257  0.680485       0.641304\n",
       "MLPClassifier           0.717149  0.866120  0.826961  0.671502            0.833682                0.506217            0.865417  0.785304    0.717257       1.000000  0.870604       0.766336\n",
       "CatBoost                0.727090  0.819446  0.768528  0.634526            0.770239                0.540700            0.850873  0.730776    0.680485       0.870604  1.000000       0.828723\n",
       "XGBClassifier           0.722538  0.733129  0.677816  0.555555            0.683712                0.649491            0.752298  0.643281    0.641304       0.766336  0.828723       1.000000"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(en_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ft_imp = pd.DataFrame({\n",
    "    'col': en_train.columns,\n",
    "    'imp': clf.feature_importances_\n",
    "}).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.681678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.118329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn5</td>\n",
       "      <td>0.082807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.038984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.036688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.021585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.014709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn50</td>\n",
       "      <td>0.003946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn500</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn5000</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       col       imp\n",
       "5   RandomForestClassifier  0.681678\n",
       "11           XGBClassifier  0.118329\n",
       "0                     knn5  0.082807\n",
       "10                CatBoost  0.038984\n",
       "9            MLPClassifier  0.036688\n",
       "6       AdaBoostClassifier  0.021585\n",
       "8               GaussianNB  0.014709\n",
       "1                    knn50  0.003946\n",
       "4       LogisticRegression  0.000446\n",
       "2                   knn500  0.000390\n",
       "7                      SVC  0.000253\n",
       "3                  knn5000  0.000185"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ft_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict_proba(en_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.869682041758683\n",
      "mcc =  0.49024669104854995\n",
      "loss =  0.30488173033899657\n"
     ]
    }
   ],
   "source": [
    "print(\"auc = \", sklearn.metrics.roc_auc_score(y_val, pred[:,1]))\n",
    "print(\"mcc = \", sklearn.metrics.matthews_corrcoef(y_val, np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(y_val, pred, labels=[0, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.7080238238640166\n",
      "mcc =  0.480781309298576\n",
      "loss =  3.624581234815747\n"
     ]
    }
   ],
   "source": [
    "# pred = en_val.mean(axis=1).tolist()\n",
    "\n",
    "pred_label = (en_val.mean(axis=1) > 0.5).astype('int').tolist()\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(y_val, pred))\n",
    "print(\"mcc = \", sklearn.metrics.matthews_corrcoef(y_val, pred_label))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(y_val, pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcc =  0.5224347157193547\n"
     ]
    }
   ],
   "source": [
    "pred_label = en_val['CatBoost'].tolist()\n",
    "print(\"mcc = \", sklearn.metrics.matthews_corrcoef(y_val, pred_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      5860\n",
      "           1       0.75      0.44      0.56      1020\n",
      "\n",
      "    accuracy                           0.90      6880\n",
      "   macro avg       0.83      0.71      0.75      6880\n",
      "weighted avg       0.89      0.90      0.88      6880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_val, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66659, 14)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55970, 14)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =model.predict_proba(X_test)\n",
    "sub_label = np.argmax(sub, axis=1)\n",
    "sub_df = pd.read_csv('data/sample_submission_0_1.csv')\n",
    "sub_df['open_flag'] = sub_label\n",
    "sub_df.to_csv(f'sub_val_{mcc}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55970"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
